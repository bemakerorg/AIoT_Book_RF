{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONkZzXzNSjR8BoL0aHaiot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bemakerorg/AIoT_Book_RF/blob/main/AIoT_RF_Book_ES_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ESERCIZIO 16 - AUTOMOBILE O GATTO?**"
      ],
      "metadata": {
        "id": "6dnYM7GodYNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importiamo la libreria TensorFlow per costruire e addestrare modelli di deep learning\n",
        "import tensorflow as tf\n",
        "# Importiamo il modulo tensorflow_datasets per accedere ai dataset preconfezionati\n",
        "import tensorflow_datasets as tfds\n",
        "# Importiamo matplotlib.pyplot per visualizzare grafici e immagini\n",
        "import matplotlib.pyplot as plt\n",
        "# Importiamo Sequential, un modello di rete neurale semplice da usare in Keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Importiamo i vari strati necessari per costruire la rete neurale\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Dropout\n",
        "# Importiamo l2 per applicare la regolarizzazione L2, che aiuta a prevenire l'overfitting\n",
        "from tensorflow.keras.regularizers import l2\n",
        "# Importiamo EarlyStopping, un callback per fermare l'addestramento se il modello smette di migliorare\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Importiamo Adam, un algoritmo di ottimizzazione efficace usato comunemente nel deep learning\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "2PU6ADb2VuL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carica il dataset CIFAR-10 da tensorflow_datasets\n",
        "# split=['train', 'test'] separa il dataset in dati di addestramento e di test\n",
        "# shuffle_files=True mescola i file per garantire che i dati siano randomizzati\n",
        "# as_supervised=True restituisce le tuple (immagine, etichetta)\n",
        "# with_info=True restituisce anche le informazioni sul dataset, come il numero di classi e la dimensione dell'immagine\n",
        "(train_ds, test_ds), ds_info = tfds.load('cifar10', split=['train', 'test'], shuffle_files=True, as_supervised=True, with_info=True)\n",
        "\n",
        "# Definisce una funzione per filtrare le immagini delle automobili nel dataset\n",
        "def filter_automobiles(image, label):\n",
        "    return tf.equal(label, 1)  # 1 è l'etichetta per 'automobile' nel dataset CIFAR-10\n",
        "\n",
        "# Definisce una funzione per filtrare le immagini dei gatti nel dataset\n",
        "def filter_cats(image, label):\n",
        "    return tf.equal(label, 3)  # 3 è l'etichetta per 'gatto' nel dataset CIFAR-10\n",
        "\n",
        "# Filtra il dataset di addestramento per ottenere solo le immagini delle automobili\n",
        "train_ds_cars = train_ds.filter(filter_automobiles)\n",
        "\n",
        "# Filtra il dataset di test per ottenere solo le immagini delle automobili\n",
        "test_ds_cars = test_ds.filter(filter_automobiles)\n",
        "\n",
        "# Filtra il dataset di addestramento per ottenere solo le immagini dei gatti\n",
        "train_ds_cats = train_ds.filter(filter_cats)\n",
        "\n",
        "# Filtra il dataset di test per ottenere solo le immagini dei gatti\n",
        "test_ds_cats = test_ds.filter(filter_cats)\n",
        "\n",
        "# Funzione per creare un dataset combinato di gatti e automobili\n",
        "def create_combined_dataset(cat_ds, car_ds):\n",
        "    # Cambia l'etichetta dei gatti in 0\n",
        "    cat_ds = cat_ds.map(lambda image, label: (image, tf.constant(0, dtype=tf.int32)))\n",
        "\n",
        "    # Cambia l'etichetta delle automobili in 1\n",
        "    car_ds = car_ds.map(lambda image, label: (image, tf.constant(1, dtype=tf.int32)))\n",
        "\n",
        "    # Concatenazione dei dataset di gatti e automobili\n",
        "    combined_ds = cat_ds.concatenate(car_ds)\n",
        "\n",
        "    # Mescola il dataset, imposta la dimensione del batch, normalizza le immagini dividendo i pixel per 255\n",
        "    # Prefetching automatico per migliorare le prestazioni del training\n",
        "    combined_ds = combined_ds.shuffle(10000).batch(32).map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y)).prefetch(tf.data.AUTOTUNE)\n",
        "    return combined_ds\n",
        "\n",
        "# Crea il dataset combinato di addestramento per gatti e automobili\n",
        "train_ds_combined = create_combined_dataset(train_ds_cats, train_ds_cars)\n",
        "\n",
        "# Crea il dataset combinato di test per gatti e automobili\n",
        "test_ds_combined = create_combined_dataset(test_ds_cats, test_ds_cars)\n"
      ],
      "metadata": {
        "id": "OjogtcplVz0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione per applicare tecniche di data augmentation alle immagini\n",
        "def augment_data(image, label):\n",
        "    # Esegue un flip casuale orizzontale sull'immagine\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    # Modifica casualmente la luminosità dell'immagine, max_delta indica la variazione massima\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    # Modifica casualmente il contrasto dell'immagine, con valori compresi tra 0.9 e 1.1\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "\n",
        "    # Restituisce l'immagine modificata e la sua etichetta\n",
        "    return image, label\n",
        "\n",
        "# Applica la funzione di data augmentation al dataset combinato di addestramento\n",
        "train_ds_combined = train_ds_combined.map(\n",
        "    # Per ogni batch di immagini ed etichette, applica la funzione di data augmentation\n",
        "    lambda x, y: (\n",
        "        tf.map_fn(lambda img: augment_data(img, y)[0], x), # Applica augment_data a ciascuna immagine nel batch\n",
        "        y # Mantiene le etichette invariate\n",
        "    )\n",
        ").prefetch(tf.data.AUTOTUNE) # Prefetching automatico per migliorare le prestazioni durante l'addestramento\n"
      ],
      "metadata": {
        "id": "_plgb4UUWM2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisce un modello di rete neurale convoluzionale (CNN) sequenziale\n",
        "model = Sequential([\n",
        "    # Strato di input che definisce la forma delle immagini in input: 32x32 pixel con 3 canali di colore (RGB)\n",
        "    Input(shape=(32, 32, 3)),\n",
        "\n",
        "    # Primo strato convoluzionale con 32 filtri 3x3, funzione di attivazione ReLU e regolarizzazione L2\n",
        "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "\n",
        "    # Strato di pooling che riduce la dimensionalità spaziale dell'input (downsampling) con una finestra 2x2\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Strato di dropout che disattiva casualmente il 25% dei neuroni per prevenire l'overfitting\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Secondo strato convoluzionale con 64 filtri 3x3, funzione di attivazione ReLU e regolarizzazione L2\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "\n",
        "    # Strato di pooling che riduce la dimensionalità spaziale dell'input con una finestra 2x2\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Strato di dropout che disattiva casualmente il 25% dei neuroni per prevenire l'overfitting\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Terzo strato convoluzionale con 128 filtri 3x3, funzione di attivazione ReLU e regolarizzazione L2\n",
        "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "\n",
        "    # Strato di pooling che riduce la dimensionalità spaziale dell'input con una finestra 2x2\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Strato di Flatten che trasforma i dati 2D in un array 1D per collegarli agli strati densi\n",
        "    Flatten(),\n",
        "\n",
        "    # Strato denso (fully connected) con 128 neuroni, funzione di attivazione ReLU e regolarizzazione L2\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "\n",
        "    # Strato di dropout che disattiva casualmente il 50% dei neuroni per prevenire l'overfitting\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Strato denso (fully connected) con 64 neuroni, funzione di attivazione ReLU e regolarizzazione L2\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "\n",
        "    # Strato di dropout che disattiva casualmente il 50% dei neuroni per prevenire l'overfitting\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Strato denso finale con 2 neuroni (uno per ciascuna classe), funzione di attivazione softmax per classificazione\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compila il modello specificando l'algoritmo di ottimizzazione Adam con un tasso di apprendimento ridotto\n",
        "# Utilizza 'sparse_categorical_crossentropy' come funzione di loss e 'accuracy' come metrica\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Stampa un riepilogo del modello, mostrando la struttura degli strati e i parametri di addestramento\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "lZ_TpcMXWS4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBrQHBkCOGvI"
      },
      "outputs": [],
      "source": [
        "# Definisce un callback di early stopping per interrompere l'addestramento quando la performance del modello si stabilizza\n",
        "# monitor='val_loss' monitora la perdita di validazione per determinare il momento di interrompere l'addestramento\n",
        "# patience=3 consente al processo di addestramento di continuare per 3 epoche aggiuntive dopo l'ultima riduzione della perdita\n",
        "# restore_best_weights=True ripristina i pesi del modello al miglior checkpoint di validazione raggiunto durante l'addestramento\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Addestra il modello utilizzando il dataset di addestramento combinato\n",
        "# epochs=20 specifica il numero massimo di epoche di addestramento\n",
        "# validation_data=test_ds_combined utilizza il dataset di test combinato per validazione durante l'addestramento\n",
        "# callbacks=[early_stopping] applica il callback di early stopping per interrompere l'addestramento quando necessario\n",
        "history = model.fit(train_ds_combined, epochs=20, validation_data=test_ds_combined, callbacks=[early_stopping])\n",
        "\n",
        "# Valuta il modello sul dataset di test combinato\n",
        "# Restituisce la perdita di test e l'accuratezza\n",
        "test_loss, test_acc = model.evaluate(test_ds_combined)\n",
        "\n",
        "# Stampa l'accuratezza di test\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Definisce una funzione per tracciare i grafici della perdita e dell'accuratezza durante l'addestramento\n",
        "def plot_history(history):\n",
        "    # Estrae i dati di accuratezza e perdita dall'oggetto history\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # Crea un range di epoche per l'asse x\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    # Imposta le dimensioni della figura del grafico\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Grafico dell'accuratezza di addestramento e validazione\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'bo-', label='Accuratezza Addestramento')  # Linea blu per l'accuratezza di addestramento\n",
        "    plt.plot(epochs, val_acc, 'ro-', label='Accuratezza Validazione')  # Linea rossa per l'accuratezza di validazione\n",
        "    plt.title('Accuratezza Addestramento e Validazione')  # Titolo del grafico\n",
        "    plt.legend()  # Mostra la legenda\n",
        "\n",
        "    # Grafico della perdita di addestramento e validazione\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'bo-', label='Perdita Addestramento')  # Linea blu per la perdita di addestramento\n",
        "    plt.plot(epochs, val_loss, 'ro-', label='Perdita Validazione')  # Linea rossa per la perdita di validazione\n",
        "    plt.title('Perdita Addestramento e Validazione')  # Titolo del grafico\n",
        "    plt.legend()  # Mostra la legenda\n",
        "\n",
        "    # Mostra i grafici\n",
        "    plt.show()\n",
        "\n",
        "# Chiama la funzione plot_history per stampare i grafici\n",
        "plot_history(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa le librerie necessarie\n",
        "from google.colab import files  # Per caricare file da locale in Google Colab\n",
        "from tensorflow.keras.preprocessing import image  # Per la manipolazione delle immagini\n",
        "import numpy as np  # Libreria per la manipolazione degli array\n",
        "import matplotlib.pyplot as plt  # Libreria per la visualizzazione grafica\n",
        "\n",
        "# Carica le immagini dal tuo PC\n",
        "uploaded = files.upload()  # Utilizza un'interfaccia di caricamento file di Google Colab\n",
        "\n",
        "# Funzione per preprocessare le immagini\n",
        "def load_and_preprocess_image(image_path):\n",
        "    # Carica l'immagine dal percorso specificato e ridimensionala a 32x32 pixel\n",
        "    img = image.load_img(image_path, target_size=(32, 32))\n",
        "\n",
        "    # Converti l'immagine in un array numpy (trasforma l'immagine in un array di pixel)\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Normalizza l'immagine per avere valori dei pixel compresi tra 0 e 1\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Aggiungi una dimensione per il batch, rendendo l'array (1, 32, 32, 3)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Restituisce l'array dell'immagine preprocessata\n",
        "    return img_array\n",
        "\n",
        "# Funzione per visualizzare e predire le immagini caricate\n",
        "def predict_and_display_images(uploaded_files):\n",
        "    # Dizionario per mappare gli indici di classe a etichette umane comprensibili\n",
        "    class_labels = {0: 'gatto', 1: 'automobile'}\n",
        "\n",
        "    # Itera su ogni immagine caricata\n",
        "    for image_path in uploaded_files:\n",
        "        # Preprocessa l'immagine\n",
        "        test_image = load_and_preprocess_image(image_path)\n",
        "\n",
        "        # Fai la previsione utilizzando il modello già addestrato\n",
        "        predictions = model.predict(test_image)\n",
        "\n",
        "        # Ottieni l'indice della classe con la probabilità più alta\n",
        "        predicted_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Recupera l'etichetta corrispondente all'indice della classe predetta\n",
        "        predicted_label = class_labels[predicted_class[0]]\n",
        "\n",
        "        # Visualizza l'immagine e la sua previsione\n",
        "        plt.figure(figsize=(5, 5))  # Imposta la dimensione della figura\n",
        "        plt.imshow(image.load_img(image_path))  # Carica e mostra l'immagine originale\n",
        "        plt.title(f\"Previsione: {predicted_label}\")  # Imposta il titolo della figura come la previsione\n",
        "        plt.axis('off')  # Rimuove gli assi dalla visualizzazione\n",
        "        plt.show()  # Mostra la figura\n",
        "\n",
        "# Chiama la funzione per fare previsioni sulle immagini caricate\n",
        "predict_and_display_images(uploaded.keys())\n"
      ],
      "metadata": {
        "id": "6_jVnP36B-Gl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}